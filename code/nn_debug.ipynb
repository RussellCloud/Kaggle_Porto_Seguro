{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:       16432484      688724    15472584        5360      271176    15417664\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "! free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from time import time\n",
    "import datetime\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from util import Gini, interaction_features\n",
    "from itertools import combinations\n",
    "from util import proj_num_on_cat\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv_only = True\n",
    "save_cv = True\n",
    "\n",
    "NFOLDS = 5\n",
    "kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "train = pd.read_csv(\"/input/data/train.csv\")\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "del train['target'], train['id']\n",
    "\n",
    "test = pd.read_csv(\"/input/data/test.csv\")\n",
    "test_id = test['id']\n",
    "del test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cat_fea = [x for x in list(train) if 'cat' in x]\n",
    "bin_fea = [x for x in list(train) if 'bin' in x]\n",
    "\n",
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# include interactions\n",
    "for e, (x, y) in enumerate(combinations(['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01'], 2)):\n",
    "    train, test = interaction_features(train, test, x, y, e)\n",
    "\n",
    "num_features = [c for c in list(train) if ('cat' not in c and 'calc' not in c)]\n",
    "num_features.append('missing')\n",
    "inter_fea = [x for x in list(train) if 'inter' in x]\n",
    "\n",
    "feature_names = list(train)\n",
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "count = 0\n",
    "for c in ind_features:\n",
    "    if count == 0:\n",
    "        train['new_ind'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        train['new_ind'] += '_' + train[c].astype(str)\n",
    "\n",
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "count = 0\n",
    "for c in ind_features:\n",
    "    if count == 0:\n",
    "        test['new_ind'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        test['new_ind'] += '_' + test[c].astype(str)\n",
    "\n",
    "reg_features = [c for c in feature_names if 'reg' in c]\n",
    "count = 0\n",
    "for c in reg_features:\n",
    "    if count == 0:\n",
    "        train['new_reg'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        train['new_reg'] += '_' + train[c].astype(str)\n",
    "\n",
    "reg_features = [c for c in feature_names if 'reg' in c]\n",
    "count = 0\n",
    "for c in reg_features:\n",
    "    if count == 0:\n",
    "        test['new_reg'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        test['new_reg'] += '_' + test[c].astype(str)\n",
    "\n",
    "car_features = [c for c in feature_names if 'car' in c]\n",
    "count = 0\n",
    "for c in car_features:\n",
    "    if count == 0:\n",
    "        train['new_car'] = train[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        train['new_car'] += '_' + train[c].astype(str)\n",
    "\n",
    "car_features = [c for c in feature_names if 'car' in c]\n",
    "count = 0\n",
    "for c in car_features:\n",
    "    if count == 0:\n",
    "        test['new_car'] = test[c].astype(str)\n",
    "        count += 1\n",
    "    else:\n",
    "        test['new_car'] += '_' + test[c].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "train_cat = train[cat_fea]\n",
    "train_num = train[[x for x in list(train) if x in num_features]]\n",
    "test_cat = test[cat_fea]\n",
    "test_num = test[[x for x in list(train) if x in num_features]]\n",
    "\n",
    "max_cat_values = []\n",
    "for c in cat_fea:\n",
    "    le = LabelEncoder()\n",
    "    x = le.fit_transform(pd.concat([train_cat, test_cat])[c])\n",
    "    train_cat[c] = le.transform(train_cat[c])\n",
    "    test_cat[c] = le.transform(test_cat[c])\n",
    "    max_cat_values.append(np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_01          int64\n",
      "ps_ind_03          int64\n",
      "ps_ind_06_bin      int64\n",
      "ps_ind_07_bin      int64\n",
      "ps_ind_08_bin      int64\n",
      "ps_ind_09_bin      int64\n",
      "ps_ind_10_bin      int64\n",
      "ps_ind_11_bin      int64\n",
      "ps_ind_12_bin      int64\n",
      "ps_ind_13_bin      int64\n",
      "ps_ind_14          int64\n",
      "ps_ind_15          int64\n",
      "ps_ind_16_bin      int64\n",
      "ps_ind_17_bin      int64\n",
      "ps_ind_18_bin      int64\n",
      "ps_reg_01        float64\n",
      "ps_reg_02        float64\n",
      "ps_reg_03        float64\n",
      "ps_car_11          int64\n",
      "ps_car_12        float64\n",
      "ps_car_13        float64\n",
      "ps_car_14        float64\n",
      "ps_car_15        float64\n",
      "missing          float64\n",
      "inter_0*         float64\n",
      "inter_0/         float64\n",
      "inter_1*         float64\n",
      "inter_1/         float64\n",
      "inter_2*         float64\n",
      "inter_2/         float64\n",
      "inter_3*         float64\n",
      "inter_3/         float64\n",
      "inter_4*         float64\n",
      "inter_4/         float64\n",
      "inter_5*         float64\n",
      "inter_5/         float64\n",
      "inter_6*           int64\n",
      "inter_6/         float64\n",
      "inter_7*         float64\n",
      "inter_7/         float64\n",
      "inter_8*           int64\n",
      "inter_8/         float64\n",
      "inter_9*         float64\n",
      "inter_9/         float64\n",
      "inter_10*        float64\n",
      "inter_10/        float64\n",
      "inter_11*        float64\n",
      "inter_11/        float64\n",
      "inter_12*        float64\n",
      "inter_12/        float64\n",
      "inter_13*          int64\n",
      "inter_13/        float64\n",
      "inter_14*        float64\n",
      "inter_14/        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# xgboost prediction\n",
    "train_fea0, test_fea0 = pickle.load(open(\"/input/data/fea0.pk\"))\n",
    "\n",
    "cat_count_features = []\n",
    "for c in cat_fea + ['new_ind','new_reg','new_car']:\n",
    "    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n",
    "    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n",
    "    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n",
    "    cat_count_features.append('%s_count'%c)\n",
    "\n",
    "\n",
    "print(train_num.dtypes)\n",
    "train_list = [train_num.replace([np.inf, -np.inf, np.nan], 0), train[cat_count_features], train_fea0]\n",
    "test_list = [test_num.replace([np.inf, -np.inf, np.nan], 0), test[cat_count_features], test_fea0]\n",
    "\n",
    "del train_num,test_num\n",
    "del train_fea0,test_fea0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n",
      "((595212, 6), (892816, 6))\n"
     ]
    }
   ],
   "source": [
    "#feature aggregation\n",
    "for t in ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01']:\n",
    "    for g in ['ps_car_13', 'ps_ind_03', 'ps_reg_03', 'ps_ind_15', 'ps_reg_01', 'ps_ind_01', 'ps_ind_05_cat']:\n",
    "        if t != g:\n",
    "            s_train, s_test = proj_num_on_cat(train, test, target_column=t, group_column=g)\n",
    "            train_list.append(s_train)\n",
    "            test_list.append(s_test)\n",
    "            del s_train,s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:       16432484     7255776     7057624        5380     2119084     8841504\r\n",
      "Swap:             0           0           0\r\n"
     ]
    }
   ],
   "source": [
    "! free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<595212x325 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 170600225 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.hstack(train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "X = sparse.hstack(train_list).tocsr()\n",
    "X_test = sparse.hstack(test_list).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "all_data = np.vstack([X.toarray(), X_test.toarray()])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data)\n",
    "X = scaler.transform(X.toarray())\n",
    "X_test = scaler.transform(X_test.toarray())\n",
    "print(X.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
